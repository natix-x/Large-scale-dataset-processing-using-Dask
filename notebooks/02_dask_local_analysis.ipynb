{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1768349a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\node.py:187: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 50333 instead\n",
      "  warnings.warn(\n",
      "c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\contextlib.py:144: UserWarning: Creating scratch directories is taking a surprisingly long time. (1.51s) This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask client connected\n",
      "<Client: 'tcp://127.0.0.1:50337' processes=2 threads=4, memory=3.73 GiB>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 01:16:33,237 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:50348 (pid=14908) exceeded 95% memory budget. Restarting...\n",
      "2025-06-11 01:16:33,866 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:50348' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_parquet-103a5c4fbd3be517d41db400c7e7a2ae', 3), ('read_parquet-103a5c4fbd3be517d41db400c7e7a2ae', 5), ('chunk-4c44b446e9669427487472b80f5fc66c', 1)} (stimulus_id='handle-worker-cleanup-1749597393.8647346')\n",
      "2025-06-11 01:16:34,509 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:50351 (pid=9860) exceeded 95% memory budget. Restarting...\n",
      "2025-06-11 01:16:34,600 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-06-11 01:16:34,695 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:50351' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_parquet-103a5c4fbd3be517d41db400c7e7a2ae', 4), ('read_parquet-103a5c4fbd3be517d41db400c7e7a2ae', 2)} (stimulus_id='handle-worker-cleanup-1749597394.695037')\n",
      "2025-06-11 01:16:35,324 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-06-11 01:16:48,391 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:50378 (pid=18968) exceeded 95% memory budget. Restarting...\n",
      "2025-06-11 01:16:55,155 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:50378' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_parquet-103a5c4fbd3be517d41db400c7e7a2ae', 1)} (stimulus_id='handle-worker-cleanup-1749597415.1546495')\n",
      "2025-06-11 01:16:57,716 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-06-11 01:17:00,065 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:50381 (pid=10468) exceeded 95% memory budget. Restarting...\n",
      "2025-06-11 01:17:00,180 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:50381' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_parquet-103a5c4fbd3be517d41db400c7e7a2ae', 3), ('read_parquet-103a5c4fbd3be517d41db400c7e7a2ae', 0)} (stimulus_id='handle-worker-cleanup-1749597420.1798663')\n",
      "2025-06-11 01:17:00,631 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-06-11 01:17:08,097 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:50396 (pid=4292) exceeded 95% memory budget. Restarting...\n",
      "2025-06-11 01:17:14,239 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:50396' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_parquet-103a5c4fbd3be517d41db400c7e7a2ae', 1)} (stimulus_id='handle-worker-cleanup-1749597434.2385285')\n",
      "2025-06-11 01:17:14,698 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-06-11 01:17:15,193 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:50403 (pid=5600) exceeded 95% memory budget. Restarting...\n",
      "2025-06-11 01:17:16,157 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:50403' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_parquet-103a5c4fbd3be517d41db400c7e7a2ae', 3), ('read_parquet-103a5c4fbd3be517d41db400c7e7a2ae', 0)} (stimulus_id='handle-worker-cleanup-1749597436.1554964')\n",
      "2025-06-11 01:17:16,917 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-06-11 01:17:34,954 - tornado.application - ERROR - Exception in callback functools.partial(<function TCPServer._handle_connection.<locals>.<lambda> at 0x00000261BB41CD60>, <Task finished name='Task-148089' coro=<BaseTCPListener._handle_stream() done, defined at c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\tcp.py:655> exception=MemoryError((6073139484287059271,), dtype('uint8'))>)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\natal\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "          ^^^^^^^^^^\n",
      "  File \"C:\\Users\\natal\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\tcpserver.py\", line 387, in <lambda>\n",
      "    gen.convert_yielded(future), lambda f: f.result()\n",
      "                                           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 667, in _handle_stream\n",
      "    await self.on_connection(comm)\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 288, in on_connection\n",
      "    return await super().on_connection(comm, handshake_overrides)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 267, in on_connection\n",
      "    handshake = await comm.read()\n",
      "                ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 228, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 360, in read_bytes_rw\n",
      "    buf = host_array(n)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\protocol\\utils.py\", line 29, in host_array\n",
      "    return numpy.empty((n,), dtype=\"u1\").data\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 5.27 EiB for an array with shape (6073139484287059271,) and data type uint8\n",
      "2025-06-11 01:17:36,037 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:50428 (pid=18964) exceeded 95% memory budget. Restarting...\n",
      "2025-06-11 01:17:37,343 - tornado.application - ERROR - Exception in callback functools.partial(<function TCPServer._handle_connection.<locals>.<lambda> at 0x00000261BB41DE40>, <Task finished name='Task-148088' coro=<BaseTCPListener._handle_stream() done, defined at c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\tcp.py:655> exception=MemoryError((6073139484287059271,), dtype('uint8'))>)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\natal\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "          ^^^^^^^^^^\n",
      "  File \"C:\\Users\\natal\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\tcpserver.py\", line 387, in <lambda>\n",
      "    gen.convert_yielded(future), lambda f: f.result()\n",
      "                                           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 667, in _handle_stream\n",
      "    await self.on_connection(comm)\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 288, in on_connection\n",
      "    return await super().on_connection(comm, handshake_overrides)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 267, in on_connection\n",
      "    handshake = await comm.read()\n",
      "                ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 228, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 360, in read_bytes_rw\n",
      "    buf = host_array(n)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\protocol\\utils.py\", line 29, in host_array\n",
      "    return numpy.empty((n,), dtype=\"u1\").data\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 5.27 EiB for an array with shape (6073139484287059271,) and data type uint8\n",
      "2025-06-11 01:17:37,720 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-06-11 01:17:39,780 - tornado.application - ERROR - Exception in callback functools.partial(<function TCPServer._handle_connection.<locals>.<lambda> at 0x00000261BB3FFE20>, <Task finished name='Task-148269' coro=<BaseTCPListener._handle_stream() done, defined at c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\tcp.py:655> exception=MemoryError((6073139484287059271,), dtype('uint8'))>)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\natal\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "          ^^^^^^^^^^\n",
      "  File \"C:\\Users\\natal\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\tcpserver.py\", line 387, in <lambda>\n",
      "    gen.convert_yielded(future), lambda f: f.result()\n",
      "                                           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 667, in _handle_stream\n",
      "    await self.on_connection(comm)\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 288, in on_connection\n",
      "    return await super().on_connection(comm, handshake_overrides)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 267, in on_connection\n",
      "    handshake = await comm.read()\n",
      "                ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 228, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 360, in read_bytes_rw\n",
      "    buf = host_array(n)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natal\\PycharmProjects\\Large-scale-dataset-processing-using-Dask\\.conda\\Lib\\site-packages\\distributed\\protocol\\utils.py\", line 29, in host_array\n",
      "    return numpy.empty((n,), dtype=\"u1\").data\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 5.27 EiB for an array with shape (6073139484287059271,) and data type uint8\n",
      "2025-06-11 01:17:40,205 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:50421 (pid=9884) exceeded 95% memory budget. Restarting...\n",
      "2025-06-11 01:17:40,585 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:50421' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_parquet-103a5c4fbd3be517d41db400c7e7a2ae', 5), ('read_parquet-103a5c4fbd3be517d41db400c7e7a2ae', 1)} (stimulus_id='handle-worker-cleanup-1749597460.5855634')\n",
      "2025-06-11 01:17:40,958 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-06-11 01:17:51,273 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:50443 (pid=3248) exceeded 95% memory budget. Restarting...\n",
      "2025-06-11 01:17:51,673 - distributed.scheduler - ERROR - Task ('read_parquet-103a5c4fbd3be517d41db400c7e7a2ae', 4) marked as failed because 4 workers died while trying to run it\n",
      "2025-06-11 01:17:53,015 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-06-11 01:33:15,249 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 8799aab009753958d352ce88d48b2127 initialized by task ('shuffle-transfer-8799aab009753958d352ce88d48b2127', 0) executed on worker tcp://127.0.0.1:50466\n",
      "2025-06-11 01:33:17,587 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 8799aab009753958d352ce88d48b2127 deactivated due to stimulus 'task-finished-1749598397.3269286'\n",
      "2025-06-11 01:38:49,161 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 6958e79b9a0b03276817934ea4ba9e37 initialized by task ('shuffle-transfer-6958e79b9a0b03276817934ea4ba9e37', 2) executed on worker tcp://127.0.0.1:50466\n",
      "2025-06-11 01:38:50,971 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 6958e79b9a0b03276817934ea4ba9e37 deactivated due to stimulus 'task-finished-1749598730.8962977'\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "from dask import dataframe as dd\n",
    "\n",
    "cluster = LocalCluster(\n",
    "    n_workers=2,\n",
    "    threads_per_worker=2,\n",
    "    memory_limit='4GB'  \n",
    ")\n",
    "client = Client(cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37d7f513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask client connected\n",
      "http://127.0.0.1:50333/status\n"
     ]
    }
   ],
   "source": [
    "print(\"Dask client connected\")\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46673b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_parquet(\"../data/yellow_tripdata_2024-*.parquet\", blockszie=\"65MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2713d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41,169,720 rows × 19 columns\n"
     ]
    }
   ],
   "source": [
    "n_rows = df.shape[0].compute()\n",
    "n_cols = df.shape[1]\n",
    "print(f\"{n_rows:,} rows × {n_cols} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70df2bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
      "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
      "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
      "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
      "       'total_amount', 'congestion_surcharge', 'Airport_fee'],\n",
      "      dtype='object')\n",
      "Partition number: 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns:\", df.columns)\n",
    "print(\"Partition number:\", df.npartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac7f03a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-01 00:57:55</td>\n",
       "      <td>2024-01-01 01:17:43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>17.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.70</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:03:00</td>\n",
       "      <td>2024-01-01 00:09:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>140</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:17:06</td>\n",
       "      <td>2024-01-01 00:35:01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>23.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:36:38</td>\n",
       "      <td>2024-01-01 00:44:56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:46:51</td>\n",
       "      <td>2024-01-01 00:52:57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>211</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2024-01-01 00:57:55   2024-01-01 01:17:43              1.0   \n",
       "1         1  2024-01-01 00:03:00   2024-01-01 00:09:36              1.0   \n",
       "2         1  2024-01-01 00:17:06   2024-01-01 00:35:01              1.0   \n",
       "3         1  2024-01-01 00:36:38   2024-01-01 00:44:56              1.0   \n",
       "4         1  2024-01-01 00:46:51   2024-01-01 00:52:57              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           1.72         1.0                  N           186            79   \n",
       "1           1.80         1.0                  N           140           236   \n",
       "2           4.70         1.0                  N           236            79   \n",
       "3           1.40         1.0                  N            79           211   \n",
       "4           0.80         1.0                  N           211           148   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2         17.7    1.0      0.5        0.00           0.0   \n",
       "1             1         10.0    3.5      0.5        3.75           0.0   \n",
       "2             1         23.3    3.5      0.5        3.00           0.0   \n",
       "3             1         10.0    3.5      0.5        2.00           0.0   \n",
       "4             1          7.9    3.5      0.5        3.20           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \n",
       "0                    1.0         22.70                   2.5          0.0  \n",
       "1                    1.0         18.75                   2.5          0.0  \n",
       "2                    1.0         31.30                   2.5          0.0  \n",
       "3                    1.0         17.00                   2.5          0.0  \n",
       "4                    1.0         16.10                   2.5          0.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "672c1454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['tpep_pickup_datetime'].dt.month\n",
    "df['trip_distance_km'] = df['trip_distance'] * 1.60934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35b35a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_per_month = df.groupby('month').size().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9df2c578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month\n",
       "1     2964637\n",
       "2     3007534\n",
       "3     3582613\n",
       "4     3514295\n",
       "5     3723843\n",
       "12    3668381\n",
       "6     3539172\n",
       "7     3076876\n",
       "8     2979192\n",
       "9     3633025\n",
       "10    3833780\n",
       "11    3646372\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "courses_per_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cabe9d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_count\n",
       "3.0     1282073\n",
       "5.0      320613\n",
       "7.0          56\n",
       "8.0         192\n",
       "0.0      401354\n",
       "1.0    28632703\n",
       "2.0     5410774\n",
       "4.0      814889\n",
       "6.0      215798\n",
       "9.0          36\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"passenger_count\"].value_counts().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dd21501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(17.46790819887367)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['trip_duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "df['trip_duration'].mean().compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046f694e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
